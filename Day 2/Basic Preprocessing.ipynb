{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb8ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The Moon is a barren, rocky world without air and water. It has dark lava plain on its surface. The Moon is filled wit craters. It has no light of its own. It gets its light from the Sun. The Moo keeps changing its shape as it moves round the Earth. It spins on its axis in 27.3 days stars were named after the Edwin Aldrin were the first ones to set their foot on the Moon on 21 July 1969 They reached the Moon in their space craft named Apollo II.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08edc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import nltk \n",
    "import re \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize,WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from unidecode import unidecode\n",
    "from contractions import fix\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227ec63",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ace620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Moon is a barren, rocky world without air and water.',\n",
       " 'It has dark lava plain on its surface.',\n",
       " 'The Moon is filled wit craters.',\n",
       " 'It has no light of its own.',\n",
       " 'It gets its light from the Sun.',\n",
       " 'The Moo keeps changing its shape as it moves round the Earth.',\n",
       " 'It spins on its axis in 27.3 days stars were named after the Edwin Aldrin were the first ones to set their foot on the Moon on 21 July 1969 They reached the Moon in their space craft named Apollo II.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. sentence tokenization - punctuation,conjunction,syntax\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054cfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. word tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61142486",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " '.',\n",
       " 'The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '.',\n",
       " 'It',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Sun',\n",
       " '.',\n",
       " 'The',\n",
       " 'Moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'Earth',\n",
       " '.',\n",
       " 'It',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'Edwin',\n",
       " 'Aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'July',\n",
       " '1969',\n",
       " 'They',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'Apollo',\n",
       " 'II',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0525573",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren,',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface.',\n",
       " 'The',\n",
       " 'Moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own.',\n",
       " 'It',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Sun.',\n",
       " 'The',\n",
       " 'Moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'Earth.',\n",
       " 'It',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'Edwin',\n",
       " 'Aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'July',\n",
       " '1969',\n",
       " 'They',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'Moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'Apollo',\n",
       " 'II.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1 = WhitespaceTokenizer().tokenize(text)\n",
    "tokens1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249954b",
   "metadata": {},
   "source": [
    "# Contraction Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c14ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not like the movie'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"I don't like the movie\"\n",
    "fixed_text = fix(example)\n",
    "fixed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2ef28",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbb5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text = [i.lower() for i in tokens ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b17a24c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " '.',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '.',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " '.',\n",
       " 'the',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.',\n",
       " 'it',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'they',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce01c33",
   "metadata": {},
   "source": [
    "# Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12149421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f6d947",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " 'it',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " 'it',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'the',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'it',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'they',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_without_punct = [i for i in lower_text if i not in punctuation]\n",
    "words_without_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06d7ca",
   "metadata": {},
   "source": [
    "# stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27438b1c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdf1830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.remove(\"no\")\n",
    "stopword_list.remove(\"nor\")\n",
    "stopword_list.remove(\"not\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88cb9b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surface',\n",
       " 'moon',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " 'no',\n",
       " 'light',\n",
       " 'gets',\n",
       " 'light',\n",
       " 'sun',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'shape',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'earth',\n",
       " 'spins',\n",
       " 'axis',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'named',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'reached',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_without_stop = [i for i in words_without_punct if i not in stopword_list]\n",
    "text_without_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4915d",
   "metadata": {},
   "source": [
    "# Handling accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e283495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a, e, i, o, u, A, E, I, O, U'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"à, è, ì, ò, ù, À, È, Ì, Ò, Ù\"\n",
    "fixed_text = unidecode(example)\n",
    "fixed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e6081",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags \n",
    "# random characters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee041f",
   "metadata": {},
   "source": [
    "# Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec14b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word moon\n",
      "stemmed_word moon\n",
      "lemmatized_word moon\n",
      "****************************************************************************************************\n",
      "Original word barren\n",
      "stemmed_word bar\n",
      "lemmatized_word barren\n",
      "****************************************************************************************************\n",
      "Original word rocky\n",
      "stemmed_word rocky\n",
      "lemmatized_word rocky\n",
      "****************************************************************************************************\n",
      "Original word world\n",
      "stemmed_word world\n",
      "lemmatized_word world\n",
      "****************************************************************************************************\n",
      "Original word without\n",
      "stemmed_word without\n",
      "lemmatized_word without\n",
      "****************************************************************************************************\n",
      "Original word air\n",
      "stemmed_word air\n",
      "lemmatized_word air\n",
      "****************************************************************************************************\n",
      "Original word water\n",
      "stemmed_word wat\n",
      "lemmatized_word water\n",
      "****************************************************************************************************\n",
      "Original word dark\n",
      "stemmed_word dark\n",
      "lemmatized_word dark\n",
      "****************************************************************************************************\n",
      "Original word lava\n",
      "stemmed_word lav\n",
      "lemmatized_word lava\n",
      "****************************************************************************************************\n",
      "Original word plain\n",
      "stemmed_word plain\n",
      "lemmatized_word plain\n",
      "****************************************************************************************************\n",
      "Original word surface\n",
      "stemmed_word surfac\n",
      "lemmatized_word surface\n",
      "****************************************************************************************************\n",
      "Original word moon\n",
      "stemmed_word moon\n",
      "lemmatized_word moon\n",
      "****************************************************************************************************\n",
      "Original word filled\n",
      "stemmed_word fil\n",
      "lemmatized_word filled\n",
      "****************************************************************************************************\n",
      "Original word wit\n",
      "stemmed_word wit\n",
      "lemmatized_word wit\n",
      "****************************************************************************************************\n",
      "Original word craters\n",
      "stemmed_word crat\n",
      "lemmatized_word crater\n",
      "****************************************************************************************************\n",
      "Original word no\n",
      "stemmed_word no\n",
      "lemmatized_word no\n",
      "****************************************************************************************************\n",
      "Original word light\n",
      "stemmed_word light\n",
      "lemmatized_word light\n",
      "****************************************************************************************************\n",
      "Original word gets\n",
      "stemmed_word get\n",
      "lemmatized_word get\n",
      "****************************************************************************************************\n",
      "Original word light\n",
      "stemmed_word light\n",
      "lemmatized_word light\n",
      "****************************************************************************************************\n",
      "Original word sun\n",
      "stemmed_word sun\n",
      "lemmatized_word sun\n",
      "****************************************************************************************************\n",
      "Original word moo\n",
      "stemmed_word moo\n",
      "lemmatized_word moo\n",
      "****************************************************************************************************\n",
      "Original word keeps\n",
      "stemmed_word keep\n",
      "lemmatized_word keep\n",
      "****************************************************************************************************\n",
      "Original word changing\n",
      "stemmed_word chang\n",
      "lemmatized_word changing\n",
      "****************************************************************************************************\n",
      "Original word shape\n",
      "stemmed_word shap\n",
      "lemmatized_word shape\n",
      "****************************************************************************************************\n",
      "Original word moves\n",
      "stemmed_word mov\n",
      "lemmatized_word move\n",
      "****************************************************************************************************\n",
      "Original word round\n",
      "stemmed_word round\n",
      "lemmatized_word round\n",
      "****************************************************************************************************\n",
      "Original word earth\n",
      "stemmed_word ear\n",
      "lemmatized_word earth\n",
      "****************************************************************************************************\n",
      "Original word spins\n",
      "stemmed_word spin\n",
      "lemmatized_word spin\n",
      "****************************************************************************************************\n",
      "Original word axis\n",
      "stemmed_word ax\n",
      "lemmatized_word axis\n",
      "****************************************************************************************************\n",
      "Original word 27.3\n",
      "stemmed_word 27.3\n",
      "lemmatized_word 27.3\n",
      "****************************************************************************************************\n",
      "Original word days\n",
      "stemmed_word day\n",
      "lemmatized_word day\n",
      "****************************************************************************************************\n",
      "Original word stars\n",
      "stemmed_word star\n",
      "lemmatized_word star\n",
      "****************************************************************************************************\n",
      "Original word named\n",
      "stemmed_word nam\n",
      "lemmatized_word named\n",
      "****************************************************************************************************\n",
      "Original word edwin\n",
      "stemmed_word edwin\n",
      "lemmatized_word edwin\n",
      "****************************************************************************************************\n",
      "Original word aldrin\n",
      "stemmed_word aldrin\n",
      "lemmatized_word aldrin\n",
      "****************************************************************************************************\n",
      "Original word first\n",
      "stemmed_word first\n",
      "lemmatized_word first\n",
      "****************************************************************************************************\n",
      "Original word ones\n",
      "stemmed_word on\n",
      "lemmatized_word one\n",
      "****************************************************************************************************\n",
      "Original word set\n",
      "stemmed_word set\n",
      "lemmatized_word set\n",
      "****************************************************************************************************\n",
      "Original word foot\n",
      "stemmed_word foot\n",
      "lemmatized_word foot\n",
      "****************************************************************************************************\n",
      "Original word moon\n",
      "stemmed_word moon\n",
      "lemmatized_word moon\n",
      "****************************************************************************************************\n",
      "Original word 21\n",
      "stemmed_word 21\n",
      "lemmatized_word 21\n",
      "****************************************************************************************************\n",
      "Original word july\n",
      "stemmed_word july\n",
      "lemmatized_word july\n",
      "****************************************************************************************************\n",
      "Original word 1969\n",
      "stemmed_word 1969\n",
      "lemmatized_word 1969\n",
      "****************************************************************************************************\n",
      "Original word reached\n",
      "stemmed_word reach\n",
      "lemmatized_word reached\n",
      "****************************************************************************************************\n",
      "Original word moon\n",
      "stemmed_word moon\n",
      "lemmatized_word moon\n",
      "****************************************************************************************************\n",
      "Original word space\n",
      "stemmed_word spac\n",
      "lemmatized_word space\n",
      "****************************************************************************************************\n",
      "Original word craft\n",
      "stemmed_word craft\n",
      "lemmatized_word craft\n",
      "****************************************************************************************************\n",
      "Original word named\n",
      "stemmed_word nam\n",
      "lemmatized_word named\n",
      "****************************************************************************************************\n",
      "Original word apollo\n",
      "stemmed_word apollo\n",
      "lemmatized_word apollo\n",
      "****************************************************************************************************\n",
      "Original word ii\n",
      "stemmed_word ii\n",
      "lemmatized_word ii\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = LancasterStemmer()\n",
    "for i in text_without_stop:\n",
    "    stemmed_word = stemmer.stem(i)\n",
    "    lemmatized_word = lemmatizer.lemmatize(i)\n",
    "    print(f\"Original word {i}\")\n",
    "    print(f\"stemmed_word {stemmed_word}\")\n",
    "    print(f\"lemmatized_word {lemmatized_word}\")\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
